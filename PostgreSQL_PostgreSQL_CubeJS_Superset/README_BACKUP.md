# ‚ö†Ô∏è  NEN√ç  HOTOV√â: PostgreSQL DL -> PostgreSQL DW -> Cube.js -> Apache superset
 
Tento projekt implementuje kompletn√≠ analytick√Ω z√°sobn√≠k v Dockeru, zamƒõ≈ôen√Ω na **zpracov√°n√≠ a dynamick√© parsov√°n√≠ JSON dat** (typicky z IoT/MQTT zpr√°v). Vyu≈æ√≠v√° PostgreSQL/TimescaleDB pro efektivn√≠ ukl√°d√°n√≠ ƒçasov√Ωch ≈ôad a Cube.js/Superset pro vizualizaci.

**D≈Øle≈æit√©:** Toto je rozpracovan√Ω (nehotov√Ω) projekt. Sch√©ma datov√©ho skladu a ETL procesy vy≈æaduj√≠ dokonƒçen√≠.

---

## üöÄ I. Architektura a Technologie

≈òe≈°en√≠ je postaveno na kontejnerizaci a je rozdƒõleno na dvƒõ datab√°zov√© vrstvy pro ƒçist√Ω ETL proces:

1. **Data Lake (`pg-lake`):** PostgreSQL 16. Slou≈æ√≠ k surov√©mu ulo≈æen√≠ JSON dat.  
2. **Data Warehouse (`pg-warehouse`):** TimescaleDB (PostgreSQL s roz≈°√≠≈ôen√≠m pro ƒçasov√© ≈ôady). Zde prob√≠h√° ETL a dynamick√© parsov√°n√≠ JSON do strukturovan√Ωch tabulek (staging).  
3. **Semantick√° vrstva (`cube`):** Cube.js. P≈ôipojuje se k DW a definuje mƒõ≈ô√≠tka a dimenze.  
4. **Vizualizace (`superset`):** Apache Superset. Vizualizuje data z√≠skan√° p≈ôes Cube.js SQL API.

---

## üê≥ II. Spu≈°tƒõn√≠ Prost≈ôed√≠

Projekt se spou≈°t√≠ pomoc√≠ souboru `docker-compose.yml`.

### 1. Prvn√≠ spu≈°tƒõn√≠

Spu≈°tƒõn√≠ v≈°ech kontejner≈Ø na pozad√≠:

```bash
docker compose up -d
```

---

### 2. D≈Øle≈æit√© porty

| Slu≈æba | Kontejnerov√Ω port | Host port | Popis |
| :--- | :--- | :--- | :--- |
| **Data Lake (PG)** | `5432` | `5433` | Surov√° data |
| **Data Warehouse (TSDB)** | `5432` | `5434` | Strukturovan√° data, Data Warehouse |
| **Cube.js API** | `4000` | `4000` | API pro v√Ωvoj model≈Ø |
| **Cube.js SQL API** | `15432` | `15432` | P≈ô√≠stup k Cube model≈Øm p≈ôes PostgreSQL protokol |
| **Superset** | `8088` | `8088` | Vizualizaƒçn√≠ rozhran√≠ |

---

## üõ†Ô∏è III. Konfigurace a Inicializace

### 1. Inicializace datab√°z√≠

**pg-lake (5433):**  
- Automaticky se vytvo≈ô√≠ datab√°ze `datove_jezero`.  
- Data: Surov√© MQTT/IoT z√°znamy by mƒõly b√Ωt nahr√°ny (nap≈ô. pomoc√≠ SQL skript≈Ø ve slo≈æce `./lake/init`).

**pg-warehouse (5434):**  
- Automaticky se vytvo≈ô√≠ datab√°ze `datovy_sklad`.  
- Sch√©ma: Zde se nasazuj√≠ DDL skripty pro staging tabulky, kter√© jsou dynamicky vytv√°≈ôeny ETL procesem.

---

### 2. Spu≈°tƒõn√≠ ETL pro dynamick√© parsov√°n√≠ JSON

Jako middleware se pou≈æ√≠v√° **Python skript**, kter√Ω zaji≈°≈•uje dynamick√© vytv√°≈ôen√≠ sch√©matu ve *Staging* z√≥nƒõ (TimescaleDB) na z√°kladƒõ JSON payload≈Ø ze surov√©ho jezera.

- **Skript:** `pg_timescale_lake_to_staging.py`  
  (mus√≠ bƒõ≈æet mimo Docker a p≈ôipojovat se k port≈Øm `5433` a `5434`)  
- **Logika:**  
  Skript ƒçte JSON data z `pg-lake:5433`, analyzuje strukturu kl√≠ƒç≈Ø a dynamicky vytv√°≈ô√≠/upravuje tabulky v `pg-warehouse:5434` (sch√©ma *Stagingu*).

---

### 3. P≈ô√≠stup k analytick√Ωm n√°stroj≈Øm

**Superset**  
- Adresa: [http://localhost:8088](http://localhost:8088)  
- P≈ôihl√°≈°en√≠:  
  - U≈æivatel: `admin`  
  - Heslo: `tohlejeroothesloprobakalarku2025`  
- Konfigurace DB: Superset je ji≈æ nakonfigurov√°n pro p≈ôipojen√≠ k **Cube.js SQL API** (`port 15432`).

**Cube.js**  
- API: [http://localhost:4000](http://localhost:4000)  
- Modely: Definov√°ny ve slo≈æce `./cubejs`, odkazuj√≠ na tabulky v kontejneru `pg-warehouse`.

---

